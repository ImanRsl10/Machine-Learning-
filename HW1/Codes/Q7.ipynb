{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23396\\551505935.py:20: RuntimeWarning: Mean of empty slice.\n",
      "  self.mean[c] = X_c.mean(axis=0)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m nb_classifier \u001b[38;5;241m=\u001b[39m GaussianNaiveBayes()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Train the classifier\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mnb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     61\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m nb_classifier\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39mto_numpy())\n",
      "Cell \u001b[1;32mIn[62], line 20\u001b[0m, in \u001b[0;36mGaussianNaiveBayes.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m X_c \u001b[38;5;241m=\u001b[39m X[y \u001b[38;5;241m==\u001b[39m c]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_prior[c] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_c) \u001b[38;5;241m/\u001b[39m n_samples\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean[c] \u001b[38;5;241m=\u001b[39m \u001b[43mX_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance[c] \u001b[38;5;241m=\u001b[39m X_c\u001b[38;5;241m.\u001b[39mvar(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:121\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n\u001b[1;32m--> 121\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m                \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_prior = {}\n",
    "        self.mean = {}\n",
    "        self.variance = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.class_prior[c] = len(X_c) / n_samples\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.variance[c] = X_c.var(axis=0)\n",
    "\n",
    "    def _calculate_likelihood(self, X, c):\n",
    "        class_mean = self.mean[c]\n",
    "        class_var = self.variance[c]\n",
    "        numerator = np.exp(-(X - class_mean) ** 2 / (2 * class_var))\n",
    "        denominator = np.sqrt(2 * np.pi * class_var)\n",
    "        return np.prod(numerator / denominator, axis=1)\n",
    "\n",
    "    def _predict_single_sample(self, x):\n",
    "        posteriors = {}\n",
    "        for c in self.classes:\n",
    "            likelihood = self._calculate_likelihood(x, c)\n",
    "            posterior = likelihood * self.class_prior[c]\n",
    "            posteriors[c] = posterior\n",
    "        return max(posteriors, key=posteriors.get)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict_single_sample(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "data_set = pd.read_csv('./data/survey lung cancer.csv')\n",
    "data_set = data_set.replace('x', np.nan).dropna()\n",
    "\n",
    "for i in data_set.columns[2:-1]:\n",
    "    data_set[i] = data_set[i].astype(int)\n",
    "\n",
    "data_set['LUNG_CANCER'] = data_set['LUNG_CANCER'].map({'YES': 1, 'NO': 0})\n",
    "data_set['LUNG_CANCER'] = data_set['LUNG_CANCER'].map({'M': 1, 'F': 0})\n",
    "\n",
    "X = data_set.drop(columns=['LUNG_CANCER'])\n",
    "y = data_set['LUNG_CANCER']\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNaiveBayes()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X.to_numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y.to_numpy())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# data_set.iloc[:, -1] = data_set.iloc[:, -1].map({'YES': 1, 'NO': 0})\n",
    "\n",
    "# mean_values = data_set.iloc[:, 2:].mean()\n",
    "# variance_values = data_set.iloc[:, 2:].var()\n",
    "\n",
    "# gaussian_params = {}\n",
    "# for column in data_set.columns[2:-1]:\n",
    "#     mean, std = norm.fit(data_set[column])\n",
    "#     gaussian_params[column] = {'mean': mean, 'std': std}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
